{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507da33b-f320-4f79-b7e4-03c35d385f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report, roc_curve, auc, confusion_matrix\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# Paths\n",
    "BASE = r\"C:\\Users\\Raj Dhanush\\OneDrive\\Desktop\\DEEPLEARNING PROJECT\"\n",
    "TRAIN_AUDIO_DIR = os.path.join(BASE, \"depression_detection\", \"data\", \"train\")\n",
    "TEST_AUDIO_DIR  = os.path.join(BASE, \"depression_detection\", \"data\", \"test\")\n",
    "TRAIN_CSV = os.path.join(BASE, \"train_split_Depression_AVEC2017.csv\")\n",
    "TEST_CSV  = os.path.join(BASE, \"test_split_Depression_AVEC2017.csv\")\n",
    "FEATURE_DIR = os.path.join(BASE, \"depression_detection\", \"features\")\n",
    "MODEL_DIR = os.path.join(BASE, \"depression_detection\", \"models\")\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Train audio dir:\", TRAIN_AUDIO_DIR)\n",
    "print(\"Test audio dir:\", TEST_AUDIO_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d2463-bcc3-4875-9e74-41a7e81fa787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SR = 16000\n",
    "WINDOW_SEC = 5.0\n",
    "HOP_SEC = 2.5\n",
    "N_MFCC = 40\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 25\n",
    "LR = 1e-4\n",
    "PATIENCE = 6\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Feature extraction: MFCC\n",
    "def extract_mfcc(y, sr=SR, n_mfcc=N_MFCC):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc = librosa.util.normalize(mfcc)\n",
    "    return mfcc.astype(np.float32)  # (n_mfcc, frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a17431-964f-457c-865a-fb5360efa282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping already exists at: C:\\Users\\Raj Dhanush\\OneDrive\\Desktop\\DEEPLEARNING PROJECT\\depression_detection\\features\\mapping.json\n"
     ]
    }
   ],
   "source": [
    "def process_file_to_windows(wav_path, out_dir, window_sec=WINDOW_SEC, hop_sec=HOP_SEC, sr=SR):\n",
    "    y, _ = librosa.load(wav_path, sr=sr)\n",
    "    total = len(y)\n",
    "    window_samples = int(window_sec * sr)\n",
    "    hop_samples = int(hop_sec * sr)\n",
    "    starts = list(range(0, max(1, total - window_samples + 1), hop_samples))\n",
    "    if starts and (starts[-1] + window_samples < total):\n",
    "        starts.append(total - window_samples)\n",
    "    if not starts:\n",
    "        starts = [0]\n",
    "    saved = []\n",
    "    for i, s in enumerate(starts):\n",
    "        chunk = y[s:s+window_samples]\n",
    "        mfcc = extract_mfcc(chunk, sr=sr)\n",
    "        base = Path(wav_path).stem\n",
    "        fname = f\"{base}_win{i}.npy\"\n",
    "        out_path = os.path.join(out_dir, fname)\n",
    "        np.save(out_path, mfcc)\n",
    "        saved.append(out_path)\n",
    "    return saved\n",
    "\n",
    "def preprocess_all_train(train_csv=TRAIN_CSV, audio_dir=TRAIN_AUDIO_DIR, feature_dir=FEATURE_DIR):\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    df = pd.read_csv(train_csv)\n",
    "    mapping = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocess train\"):\n",
    "        pid = str(int(row['Participant_ID']))\n",
    "        wav_name = f\"{pid}_AUDIO.wav\"\n",
    "        wav_path = os.path.join(audio_dir, wav_name)\n",
    "        if not os.path.exists(wav_path):\n",
    "            print(\"Missing:\", wav_path)\n",
    "            continue\n",
    "        saved = process_file_to_windows(wav_path, feature_dir)\n",
    "        for p in saved:\n",
    "            mapping.append({\"file\": p, \"participant\": pid, \"label\": int(row[\"PHQ8_Binary\"])})\n",
    "    with open(os.path.join(feature_dir, \"mapping.json\"), \"w\") as f:\n",
    "        json.dump(mapping, f)\n",
    "    print(\"Total windows saved:\", len(mapping))\n",
    "    return mapping\n",
    "\n",
    "mapping_path = os.path.join(FEATURE_DIR, \"mapping.json\")\n",
    "if not os.path.exists(mapping_path):\n",
    "    print(\"Mapping not found — starting preprocessing (this will take time).\")\n",
    "    preprocess_all_train()\n",
    "else:\n",
    "    print(\"Mapping already exists at:\", mapping_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c56ef4-f9e0-43a6-ae65-9f8ce0c1371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows: 38682\n",
      "Example windows per participant (first 8): [('303', 394), ('304', 317), ('305', 681), ('310', 337), ('312', 315), ('313', 301), ('315', 390), ('316', 347)]\n"
     ]
    }
   ],
   "source": [
    "with open(mapping_path, \"r\") as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "print(\"Total windows:\", len(mapping))\n",
    "from collections import Counter\n",
    "cnt = Counter([m[\"participant\"] for m in mapping])\n",
    "print(\"Example windows per participant (first 8):\", list(cnt.items())[:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03264460-13ef-4dc2-827c-3ab44833c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset windows: 38682  max_frames: 313\n"
     ]
    }
   ],
   "source": [
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, mapping_json, normalize=False):\n",
    "        with open(mapping_json, \"r\") as f:\n",
    "            self.mapping = json.load(f)\n",
    "        self.max_frames = 0\n",
    "        for entry in self.mapping:\n",
    "            arr = np.load(entry[\"file\"])\n",
    "            self.max_frames = max(self.max_frames, arr.shape[1])\n",
    "        self.normalize = normalize\n",
    "        if self.normalize:\n",
    "            all_means = [np.load(e[\"file\"]).mean() for e in self.mapping]\n",
    "            self.global_mean = np.mean(all_means)\n",
    "            self.global_std = np.std(all_means) + 1e-9\n",
    "        else:\n",
    "            self.global_mean, self.global_std = 0.0, 1.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.mapping[idx]\n",
    "        arr = np.load(entry[\"file\"])\n",
    "        n_mfcc, frames = arr.shape\n",
    "        mf = self.max_frames\n",
    "        if frames < mf:\n",
    "            arr = np.pad(arr, ((0,0),(0,mf-frames)), mode='constant')\n",
    "        elif frames > mf:\n",
    "            arr = arr[:, :mf]\n",
    "        arr = (arr - self.global_mean)/self.global_std\n",
    "        x = torch.tensor(arr, dtype=torch.float).unsqueeze(0)\n",
    "        y = torch.tensor(entry[\"label\"], dtype=torch.float)\n",
    "        return x, y\n",
    "\n",
    "dataset = WindowDataset(mapping_path, normalize=False)\n",
    "print(\"Dataset windows:\", len(dataset), \" max_frames:\", dataset.max_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2580c72a-bf56-4d24-93e7-b39b13b96352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: 30789 Val windows: 7893\n"
     ]
    }
   ],
   "source": [
    "df_map = pd.DataFrame(mapping)\n",
    "participants = df_map['participant'].unique()\n",
    "part_label = df_map.groupby('participant')['label'].first().astype(int)\n",
    "\n",
    "train_parts, val_parts = train_test_split(participants, test_size=0.2, random_state=SEED, stratify=[part_label.get(p,0) for p in participants])\n",
    "\n",
    "train_idx = df_map[df_map['participant'].isin(train_parts)].index.tolist()\n",
    "val_idx   = df_map[df_map['participant'].isin(val_parts)].index.tolist()\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "print(\"Train windows:\", len(train_ds), \"Val windows:\", len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba94ecbc-9ab5-4e55-b68d-7269101eb1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBiLSTM(\n",
      "  (encoder): ConvEncoder(\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class CNNBiLSTM(nn.Module):\n",
    "    def __init__(self, n_mfcc=N_MFCC, lstm_hidden=128, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder()\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        self.lstm = None\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2*lstm_hidden,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.shape\n",
    "        feat = self.encoder(x)\n",
    "        b,c2,h2,w2 = feat.shape\n",
    "        feat = feat.permute(0,3,1,2).contiguous().view(b,w2,-1)\n",
    "        if self.lstm is None:\n",
    "            input_size = feat.shape[-1]\n",
    "            self.lstm = nn.LSTM(input_size, self.lstm_hidden, num_layers=1, batch_first=True, bidirectional=True).to(DEVICE)\n",
    "        out,_ = self.lstm(feat)\n",
    "        out = out[:,-1,:]\n",
    "        logits = self.classifier(out).squeeze(1)\n",
    "        return logits\n",
    "\n",
    "model = CNNBiLSTM().to(DEVICE)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57625e50-b321-4c6f-81fc-32788d4d56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4c48f3244f4e13a482806213fbc291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E1:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.5855 val_loss=0.5791 acc=0.7191 f1=0.0743\n",
      "Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf98afb96704b869e4b37c3cabe69f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E2:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train_loss=0.5627 val_loss=0.5749 acc=0.7287 f1=0.1501\n",
      "Saved best model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce75654d64274676a5b6320ea60c22b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E3:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train_loss=0.5197 val_loss=0.6072 acc=0.7211 f1=0.0983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7828b8c47f0c492c9f7c0aa9acf27fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E4:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train_loss=0.4597 val_loss=0.6089 acc=0.7239 f1=0.3649\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b519fc09d6f4e53aeb71f7defc83a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E5:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train_loss=0.4117 val_loss=0.6476 acc=0.6855 f1=0.3970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecc263a35c24d52942bcc62a58a5c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E6:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train_loss=0.3798 val_loss=0.7181 acc=0.6788 f1=0.3373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2556712402e7494fa3406f48c7f21970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E7:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train_loss=0.3485 val_loss=0.8468 acc=0.6002 f1=0.3907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e77288c5e5f40d9858804462855218b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train E8:   0%|          | 0/1925 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train_loss=0.3259 val_loss=0.8138 acc=0.6501 f1=0.3737\n",
      "Early stopping\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_val = float('inf')\n",
    "pat = 0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb,yb in tqdm(train_loader, desc=f\"Train E{epoch}\"):\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds,trues = [],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_loader:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            val_loss += loss.item()*xb.size(0)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds.extend(probs.tolist())\n",
    "            trues.extend(yb.cpu().numpy().tolist())\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    val_pred = [1 if p>0.5 else 0 for p in preds]\n",
    "    val_acc = accuracy_score(trues,val_pred)\n",
    "    val_f1 = f1_score(trues,val_pred,zero_division=0)\n",
    "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} acc={val_acc:.4f} f1={val_f1:.4f}\")\n",
    "\n",
    "    if val_loss<best_val:\n",
    "        best_val=val_loss\n",
    "        pat=0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR,\"best_cnn_bilstm.pth\"))\n",
    "        print(\"Saved best model.\")\n",
    "    else:\n",
    "        pat+=1\n",
    "        if pat>=PATIENCE:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ee2714-7a91-4232-839f-39f4706acb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing global mean/std...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cdd4908b424d2f8eddd24fc106544c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_global_stats(mapping_json):\n",
    "    mm = []\n",
    "    with open(mapping_json,\"r\") as f:\n",
    "        m = json.load(f)\n",
    "    for entry in tqdm(m):\n",
    "        arr = np.load(entry[\"file\"])\n",
    "        mm.append(arr.mean())\n",
    "    g_mean = float(np.mean(mm))\n",
    "    g_std = float(np.std(mm))+1e-9\n",
    "    joblib.dump({\"mean\":g_mean,\"std\":g_std}, os.path.join(MODEL_DIR,\"global_stats.pkl\"))\n",
    "    return g_mean, g_std\n",
    "\n",
    "if not os.path.exists(os.path.join(MODEL_DIR,\"global_stats.pkl\")):\n",
    "    print(\"Computing global mean/std...\")\n",
    "    compute_global_stats(mapping_path)\n",
    "else:\n",
    "    print(\"global_stats.pkl exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e7cce4-86c4-472e-87b2-23dbf3cfad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully at: C:\\Users\\Raj Dhanush\\OneDrive\\Desktop\\DEEPLEARNING PROJECT\\depression_detection\\models\\mfcc_cnn_bilstm.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Define model directory\n",
    "MODEL_DIR = r\"C:\\Users\\Raj Dhanush\\OneDrive\\Desktop\\DEEPLEARNING PROJECT\\depression_detection\\models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Save model weights\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"mfcc_cnn_bilstm.pth\")\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(f\"✅ Model saved successfully at: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cac12c4-f8ce-47e1-b6bc-dd616ba96ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded for inference.\n"
     ]
    }
   ],
   "source": [
    "model = CNNBiLSTM().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH,map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"Model loaded for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad37863-c950-4488-a413-f9d85acc14e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
